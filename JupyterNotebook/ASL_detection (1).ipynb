{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUUbbr2DDaKO",
        "outputId": "a3d352e1-e4a2-4fe1-c394-4ccf5274d906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.5.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python pandas tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "JvsiP847De5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n"
      ],
      "metadata": {
        "id": "xZptatcIER0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "PqMDmkF-Ht8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n"
      ],
      "metadata": {
        "id": "4WrVfJPkH-7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d grassknoted/asl-alphabet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5vtxRhvIDz5",
        "outputId": "61ae5c1f-f236-443b-f410-cccaa0ef4870"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q asl-alphabet.zip -d asl_data"
      ],
      "metadata": {
        "id": "elIZZdVlILjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import mediapipe as mp\n",
        "\n",
        "# Path to the ASL dataset folder\n",
        "DATA_DIR = '/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "\n",
        "# MediaPipe setup\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Output storage\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Limit to speed up\n",
        "max_images_per_class = 300\n",
        "\n",
        "# Process each class folder\n",
        "for dir_ in sorted(os.listdir(DATA_DIR)):\n",
        "    print(f\"\\nðŸ”¤ Processing letter: {dir_}\")\n",
        "    img_count = 0\n",
        "\n",
        "    for img_name in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
        "        if img_count >= max_images_per_class:\n",
        "            break\n",
        "\n",
        "        img_path = os.path.join(DATA_DIR, dir_, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue  # Skip broken images\n",
        "\n",
        "        # Resize and convert to RGB\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect hand landmarks\n",
        "        results = hands.process(img_rgb)\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            # Process only the first detected hand to maintain consistent feature vector length\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]\n",
        "            data_aux = []\n",
        "            x_ = []\n",
        "            y_ = []\n",
        "\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                x_.append(lm.x)\n",
        "                y_.append(lm.y)\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                data_aux.append(lm.x - min(x_))\n",
        "                data_aux.append(lm.y - min(y_))\n",
        "\n",
        "            data.append(data_aux)\n",
        "            labels.append(dir_)\n",
        "            img_count += 1\n",
        "\n",
        "        if img_count % 50 == 0 and img_count > 0:\n",
        "            print(f\"  âœ… {img_count} images processed for '{dir_}'\")\n",
        "\n",
        "print(f\"\\nâœ… Total samples collected: {len(data)}\")\n",
        "\n",
        "# Save as pickle file\n",
        "with open('asl_landmarks.pickle', 'wb') as f:\n",
        "    pickle.dump({'data': data, 'labels': labels}, f)\n",
        "\n",
        "print(\"\\nðŸ“¦ Saved landmark dataset as 'asl_landmarks.pickle'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYneibg6OZmK",
        "outputId": "4b3b7bdb-a59a-4c70-c5af-882237c7c1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¤ Processing letter: A\n",
            "  âœ… 50 images processed for 'A'\n",
            "  âœ… 50 images processed for 'A'\n",
            "  âœ… 100 images processed for 'A'\n",
            "  âœ… 150 images processed for 'A'\n",
            "  âœ… 200 images processed for 'A'\n",
            "  âœ… 250 images processed for 'A'\n",
            "  âœ… 300 images processed for 'A'\n",
            "\n",
            "ðŸ”¤ Processing letter: B\n",
            "  âœ… 50 images processed for 'B'\n",
            "  âœ… 100 images processed for 'B'\n",
            "  âœ… 100 images processed for 'B'\n",
            "  âœ… 150 images processed for 'B'\n",
            "  âœ… 200 images processed for 'B'\n",
            "  âœ… 250 images processed for 'B'\n",
            "  âœ… 300 images processed for 'B'\n",
            "\n",
            "ðŸ”¤ Processing letter: C\n",
            "  âœ… 50 images processed for 'C'\n",
            "  âœ… 100 images processed for 'C'\n",
            "  âœ… 150 images processed for 'C'\n",
            "  âœ… 150 images processed for 'C'\n",
            "  âœ… 200 images processed for 'C'\n",
            "  âœ… 250 images processed for 'C'\n",
            "  âœ… 300 images processed for 'C'\n",
            "\n",
            "ðŸ”¤ Processing letter: D\n",
            "  âœ… 50 images processed for 'D'\n",
            "  âœ… 100 images processed for 'D'\n",
            "  âœ… 150 images processed for 'D'\n",
            "  âœ… 150 images processed for 'D'\n",
            "  âœ… 200 images processed for 'D'\n",
            "  âœ… 250 images processed for 'D'\n",
            "  âœ… 300 images processed for 'D'\n",
            "\n",
            "ðŸ”¤ Processing letter: E\n",
            "  âœ… 50 images processed for 'E'\n",
            "  âœ… 100 images processed for 'E'\n",
            "  âœ… 150 images processed for 'E'\n",
            "  âœ… 200 images processed for 'E'\n",
            "  âœ… 250 images processed for 'E'\n",
            "  âœ… 300 images processed for 'E'\n",
            "\n",
            "ðŸ”¤ Processing letter: F\n",
            "  âœ… 50 images processed for 'F'\n",
            "  âœ… 100 images processed for 'F'\n",
            "  âœ… 150 images processed for 'F'\n",
            "  âœ… 200 images processed for 'F'\n",
            "  âœ… 250 images processed for 'F'\n",
            "  âœ… 300 images processed for 'F'\n",
            "\n",
            "ðŸ”¤ Processing letter: G\n",
            "  âœ… 50 images processed for 'G'\n",
            "  âœ… 100 images processed for 'G'\n",
            "  âœ… 150 images processed for 'G'\n",
            "  âœ… 200 images processed for 'G'\n",
            "  âœ… 250 images processed for 'G'\n",
            "  âœ… 300 images processed for 'G'\n",
            "\n",
            "ðŸ”¤ Processing letter: H\n",
            "  âœ… 50 images processed for 'H'\n",
            "  âœ… 50 images processed for 'H'\n",
            "  âœ… 100 images processed for 'H'\n",
            "  âœ… 150 images processed for 'H'\n",
            "  âœ… 200 images processed for 'H'\n",
            "  âœ… 250 images processed for 'H'\n",
            "  âœ… 300 images processed for 'H'\n",
            "\n",
            "ðŸ”¤ Processing letter: I\n",
            "  âœ… 50 images processed for 'I'\n",
            "  âœ… 100 images processed for 'I'\n",
            "  âœ… 150 images processed for 'I'\n",
            "  âœ… 150 images processed for 'I'\n",
            "  âœ… 200 images processed for 'I'\n",
            "  âœ… 250 images processed for 'I'\n",
            "  âœ… 300 images processed for 'I'\n",
            "\n",
            "ðŸ”¤ Processing letter: J\n",
            "  âœ… 50 images processed for 'J'\n",
            "  âœ… 100 images processed for 'J'\n",
            "  âœ… 100 images processed for 'J'\n",
            "  âœ… 150 images processed for 'J'\n",
            "  âœ… 200 images processed for 'J'\n",
            "  âœ… 250 images processed for 'J'\n",
            "  âœ… 300 images processed for 'J'\n",
            "\n",
            "ðŸ”¤ Processing letter: K\n",
            "  âœ… 50 images processed for 'K'\n",
            "  âœ… 100 images processed for 'K'\n",
            "  âœ… 150 images processed for 'K'\n",
            "  âœ… 200 images processed for 'K'\n",
            "  âœ… 250 images processed for 'K'\n",
            "  âœ… 300 images processed for 'K'\n",
            "\n",
            "ðŸ”¤ Processing letter: L\n",
            "  âœ… 50 images processed for 'L'\n",
            "  âœ… 100 images processed for 'L'\n",
            "  âœ… 150 images processed for 'L'\n",
            "  âœ… 200 images processed for 'L'\n",
            "  âœ… 250 images processed for 'L'\n",
            "  âœ… 300 images processed for 'L'\n",
            "\n",
            "ðŸ”¤ Processing letter: M\n",
            "  âœ… 50 images processed for 'M'\n",
            "  âœ… 50 images processed for 'M'\n",
            "  âœ… 100 images processed for 'M'\n",
            "  âœ… 150 images processed for 'M'\n",
            "  âœ… 150 images processed for 'M'\n",
            "  âœ… 150 images processed for 'M'\n",
            "  âœ… 150 images processed for 'M'\n",
            "  âœ… 150 images processed for 'M'\n",
            "  âœ… 200 images processed for 'M'\n",
            "  âœ… 200 images processed for 'M'\n",
            "  âœ… 250 images processed for 'M'\n",
            "  âœ… 250 images processed for 'M'\n",
            "  âœ… 300 images processed for 'M'\n",
            "\n",
            "ðŸ”¤ Processing letter: N\n",
            "  âœ… 50 images processed for 'N'\n",
            "  âœ… 50 images processed for 'N'\n",
            "  âœ… 100 images processed for 'N'\n",
            "  âœ… 100 images processed for 'N'\n",
            "  âœ… 150 images processed for 'N'\n",
            "  âœ… 150 images processed for 'N'\n",
            "  âœ… 200 images processed for 'N'\n",
            "  âœ… 250 images processed for 'N'\n",
            "  âœ… 300 images processed for 'N'\n",
            "\n",
            "ðŸ”¤ Processing letter: O\n",
            "  âœ… 50 images processed for 'O'\n",
            "  âœ… 100 images processed for 'O'\n",
            "  âœ… 150 images processed for 'O'\n",
            "  âœ… 150 images processed for 'O'\n",
            "  âœ… 200 images processed for 'O'\n",
            "  âœ… 250 images processed for 'O'\n",
            "  âœ… 300 images processed for 'O'\n",
            "\n",
            "ðŸ”¤ Processing letter: P\n",
            "  âœ… 50 images processed for 'P'\n",
            "  âœ… 100 images processed for 'P'\n",
            "  âœ… 150 images processed for 'P'\n",
            "  âœ… 200 images processed for 'P'\n",
            "  âœ… 200 images processed for 'P'\n",
            "  âœ… 250 images processed for 'P'\n",
            "  âœ… 300 images processed for 'P'\n",
            "\n",
            "ðŸ”¤ Processing letter: Q\n",
            "  âœ… 50 images processed for 'Q'\n",
            "  âœ… 50 images processed for 'Q'\n",
            "  âœ… 100 images processed for 'Q'\n",
            "  âœ… 150 images processed for 'Q'\n",
            "  âœ… 200 images processed for 'Q'\n",
            "  âœ… 250 images processed for 'Q'\n",
            "  âœ… 250 images processed for 'Q'\n",
            "  âœ… 250 images processed for 'Q'\n",
            "  âœ… 300 images processed for 'Q'\n",
            "\n",
            "ðŸ”¤ Processing letter: R\n",
            "  âœ… 50 images processed for 'R'\n",
            "  âœ… 50 images processed for 'R'\n",
            "  âœ… 100 images processed for 'R'\n",
            "  âœ… 150 images processed for 'R'\n",
            "  âœ… 200 images processed for 'R'\n",
            "  âœ… 250 images processed for 'R'\n",
            "  âœ… 300 images processed for 'R'\n",
            "\n",
            "ðŸ”¤ Processing letter: S\n",
            "  âœ… 50 images processed for 'S'\n",
            "  âœ… 100 images processed for 'S'\n",
            "  âœ… 150 images processed for 'S'\n",
            "  âœ… 200 images processed for 'S'\n",
            "  âœ… 250 images processed for 'S'\n",
            "  âœ… 250 images processed for 'S'\n",
            "  âœ… 300 images processed for 'S'\n",
            "\n",
            "ðŸ”¤ Processing letter: T\n",
            "  âœ… 50 images processed for 'T'\n",
            "  âœ… 50 images processed for 'T'\n",
            "  âœ… 100 images processed for 'T'\n",
            "  âœ… 150 images processed for 'T'\n",
            "  âœ… 200 images processed for 'T'\n",
            "  âœ… 200 images processed for 'T'\n",
            "  âœ… 250 images processed for 'T'\n",
            "  âœ… 250 images processed for 'T'\n",
            "  âœ… 300 images processed for 'T'\n",
            "\n",
            "ðŸ”¤ Processing letter: U\n",
            "  âœ… 50 images processed for 'U'\n",
            "  âœ… 100 images processed for 'U'\n",
            "  âœ… 150 images processed for 'U'\n",
            "  âœ… 200 images processed for 'U'\n",
            "  âœ… 250 images processed for 'U'\n",
            "  âœ… 300 images processed for 'U'\n",
            "\n",
            "ðŸ”¤ Processing letter: V\n",
            "  âœ… 50 images processed for 'V'\n",
            "  âœ… 100 images processed for 'V'\n",
            "  âœ… 100 images processed for 'V'\n",
            "  âœ… 150 images processed for 'V'\n",
            "  âœ… 200 images processed for 'V'\n",
            "  âœ… 250 images processed for 'V'\n",
            "  âœ… 250 images processed for 'V'\n",
            "  âœ… 300 images processed for 'V'\n",
            "\n",
            "ðŸ”¤ Processing letter: W\n",
            "  âœ… 50 images processed for 'W'\n",
            "  âœ… 100 images processed for 'W'\n",
            "  âœ… 150 images processed for 'W'\n",
            "  âœ… 200 images processed for 'W'\n",
            "  âœ… 200 images processed for 'W'\n",
            "  âœ… 200 images processed for 'W'\n",
            "  âœ… 250 images processed for 'W'\n",
            "  âœ… 300 images processed for 'W'\n",
            "\n",
            "ðŸ”¤ Processing letter: X\n",
            "  âœ… 50 images processed for 'X'\n",
            "  âœ… 100 images processed for 'X'\n",
            "  âœ… 150 images processed for 'X'\n",
            "  âœ… 200 images processed for 'X'\n",
            "  âœ… 250 images processed for 'X'\n",
            "  âœ… 250 images processed for 'X'\n",
            "  âœ… 300 images processed for 'X'\n",
            "\n",
            "ðŸ”¤ Processing letter: Y\n",
            "  âœ… 50 images processed for 'Y'\n",
            "  âœ… 100 images processed for 'Y'\n",
            "  âœ… 150 images processed for 'Y'\n",
            "  âœ… 200 images processed for 'Y'\n",
            "  âœ… 200 images processed for 'Y'\n",
            "  âœ… 250 images processed for 'Y'\n",
            "  âœ… 300 images processed for 'Y'\n",
            "\n",
            "ðŸ”¤ Processing letter: Z\n",
            "  âœ… 50 images processed for 'Z'\n",
            "  âœ… 100 images processed for 'Z'\n",
            "  âœ… 150 images processed for 'Z'\n",
            "  âœ… 200 images processed for 'Z'\n",
            "  âœ… 250 images processed for 'Z'\n",
            "  âœ… 300 images processed for 'Z'\n",
            "\n",
            "ðŸ”¤ Processing letter: del\n",
            "  âœ… 50 images processed for 'del'\n",
            "  âœ… 100 images processed for 'del'\n",
            "  âœ… 150 images processed for 'del'\n",
            "  âœ… 200 images processed for 'del'\n",
            "  âœ… 200 images processed for 'del'\n",
            "  âœ… 250 images processed for 'del'\n",
            "  âœ… 300 images processed for 'del'\n",
            "\n",
            "ðŸ”¤ Processing letter: nothing\n",
            "\n",
            "ðŸ”¤ Processing letter: space\n",
            "  âœ… 50 images processed for 'space'\n",
            "  âœ… 100 images processed for 'space'\n",
            "  âœ… 100 images processed for 'space'\n",
            "  âœ… 150 images processed for 'space'\n",
            "  âœ… 200 images processed for 'space'\n",
            "  âœ… 250 images processed for 'space'\n",
            "  âœ… 250 images processed for 'space'\n",
            "  âœ… 300 images processed for 'space'\n",
            "\n",
            "âœ… Total samples collected: 8413\n",
            "\n",
            "ðŸ“¦ Saved landmark dataset as 'asl_landmarks.pickle'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load your landmark data\n",
        "with open('asl_landmarks.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "X = dataset['data']\n",
        "y = dataset['labels']\n",
        "\n",
        "# Check if all data points have the same length\n",
        "lengths = [len(x) for x in X]\n",
        "if len(set(lengths)) > 1:\n",
        "    print(f\"Error: Data points have inconsistent lengths. Found lengths: {set(lengths)}\")\n",
        "    print(\"This is likely due to variations in the number of hands detected in the images.\")\n",
        "    print(\"Please revisit the data collection step (cell SYneibg6OZmK) to ensure consistent data representation.\")\n",
        "else:\n",
        "    # Split into train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train KNN model\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\nâœ… Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "    print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Save model\n",
        "    with open('asl_knn_model.pickle', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    print(\"\\nðŸ’¾ Model saved as 'asl_knn_model.pickle'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgxursYeRGzf",
        "outputId": "179f8d26-3244-4f54-e22d-ab7892920da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Accuracy: 97.33%\n",
            "\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           A       0.96      0.98      0.97        65\n",
            "           B       0.99      1.00      0.99        66\n",
            "           C       1.00      0.98      0.99        59\n",
            "           D       1.00      0.97      0.98        63\n",
            "           E       1.00      0.98      0.99        65\n",
            "           F       0.99      0.99      0.99        68\n",
            "           G       0.96      1.00      0.98        51\n",
            "           H       0.98      1.00      0.99        61\n",
            "           I       0.93      0.96      0.95        54\n",
            "           J       1.00      0.92      0.96        53\n",
            "           K       1.00      1.00      1.00        58\n",
            "           L       1.00      1.00      1.00        60\n",
            "           M       0.90      0.86      0.88        51\n",
            "           N       0.95      0.91      0.93        64\n",
            "           O       0.98      1.00      0.99        57\n",
            "           P       1.00      0.91      0.95        68\n",
            "           Q       0.95      1.00      0.98        60\n",
            "           R       0.97      0.92      0.94        62\n",
            "           S       0.92      0.97      0.94        68\n",
            "           T       1.00      0.98      0.99        66\n",
            "           U       0.91      0.98      0.95        63\n",
            "           V       1.00      0.98      0.99        55\n",
            "           W       0.98      0.96      0.97        52\n",
            "           X       0.98      1.00      0.99        65\n",
            "           Y       0.98      0.98      0.98        54\n",
            "           Z       0.95      0.98      0.96        53\n",
            "         del       1.00      1.00      1.00        52\n",
            "     nothing       1.00      1.00      1.00         1\n",
            "       space       0.99      1.00      0.99        69\n",
            "\n",
            "    accuracy                           0.97      1683\n",
            "   macro avg       0.97      0.97      0.97      1683\n",
            "weighted avg       0.97      0.97      0.97      1683\n",
            "\n",
            "\n",
            "ðŸ’¾ Model saved as 'asl_knn_model.pickle'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pickle\n",
        "import mediapipe as mp\n",
        "\n",
        "# Load trained model\n",
        "with open('asl_knn_model.pickle', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# MediaPipe setup\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5)\n",
        "mp_draw = mp.solutions.drawing_utils\n",
        "\n",
        "# Webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    h, w, _ = frame.shape\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process frame\n",
        "    results = hands.process(frame_rgb)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            data_aux = []\n",
        "            x_ = []\n",
        "            y_ = []\n",
        "\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                x_.append(lm.x)\n",
        "                y_.append(lm.y)\n",
        "\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                data_aux.append(lm.x - min(x_))\n",
        "                data_aux.append(lm.y - min(y_))\n",
        "\n",
        "            # Predict\n",
        "            prediction = model.predict([data_aux])[0]\n",
        "\n",
        "            # Draw landmarks\n",
        "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "            # Show prediction\n",
        "            cv2.putText(frame, prediction, (10, 70), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        2, (0, 255, 0), 3, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imshow(\"ASL Recognition\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Qomac1hqT3UE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}